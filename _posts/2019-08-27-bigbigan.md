---
layout: post
title:  "BigGAN + BiGAN = BigBiGAN: New State-of-the art Model In Representation Learning"
tag : Paper
date : 2019-08-27 10:05:05 +0900
comments: true
---

항상 대형모델 제목엔 소타가...
맨날 소타래

# Abstract

GAN들은 최근 매력적인 이미지 합성 결과를 달성했다.
초기에 비지도표현학습 방식을 사용한 GAN의 성공에도 불구하고, 이후엔 self-supervision(vised) 방식으로 대체되었다.
이 연구에서 우리는 이미지 생성 퀄리티의 향상이 표현학습 퍼포먼스를 상당히 향상 시키는것을 보여준다.
우리의 BigBiGAN은 SOTA 모델인 BigGAN 모델을 기반으로, 인코더를 추가하고 판별기를 수정하여 표현학습 과정을 확장하였다.
우리는 이 BigBiGAN 모델들의 representation learning 과 생성 능력을 광범위하게 평가하고, 이 생성기반모델들이 이미지넷에서의 비지도표현학습과 조건없는 이미지 생성에서 SOTA를 달성한 것을 보여준다.


# 1. Introduction

최근 몇년 동안 비전데이터 생성 모델들은 빠른 진보를 보아왔다. 이 모델들은 적은 모드, 간단한 구조, 그리고 저해상도라는 조건들에 국한되었지만, 모델링과 하드웨어의 발전으로 복잡하고 여러모드를 가지 고해상도 이미지 분포를 리얼하게 생성할 수 있는 능력을 얻게 되었다.
직관적으로, 이 특정 도메인의 데이터 생성 능력은 해당 도메인에 대한 높은 수준의 이해가 필요하다. 이 생각은 데이터가 많고 가격이 낮아져 전형적인 대부분 분류 머신러닝 모델이 예측할 라벨보다 훨씬 더 많은 정보로 구성된 이미지와 함께 오랫동안 인기를 끌고있다.
생성모델이의 발전은 명백했지만, 해결되지않는 질문이 있었다 : 이 모델이 배운 의미는 무엇이며 어떻게 그들이 표현학습에 영향을 주는지를.

원시 데이터만으로 진실을 이해하는 수준이 되려는 생성의 궁극적인 목표는 아직 거의 실현되지 않았다. 대신, 대부분 자기지도학습을 위한 대부분의 성공적인접근법은 자기지도학습이라 불리는 지도학습 분야를 적용하는 것이다. 이 접근법들은 일반적으로 데이터의 특정 부분을 변경하거나 고정하고, 누락된 정보 부분을 생성하거나 예측하는 모델을 학습하는것을 포함한다. 예를들면 [37,38] 에서는 비지도방식으로 채색하는것을 제안했고, 모델에게 입력 이미지의 색상채널에 일부분만 주고 빠진 채널을 예측하는 방식이다. 

비지도학습방식의 생성 모델들은 원래의 데이터의 어떤 수정도 필요로하지 않는 전체 데이터 분포를 모델링 하도록 학습되는 자기지도학습을 위한 매력적인 제안을 제공한다.
생성모델의 한 종류는 GAN이다. GAN 프레임웤의 생성기는 랜덤 샘플링된 latent 값으로 부터 feed-foward 맵핑을 통해 데이터를 생성하고, 실제 데이터와 생성된 데이터 샘플 사이의 차이를 학습하는 판별기가 제공하는 신호를 통해 제네레이터가 데이터의 출력이 데이터의 분포를 따르도록 안내한다. ALI(Adversirially learned inference) 혹은 BiGAN 접근법은 기본 GAN의 구조에, 실제 데이터를 latents로 맵핑하는 인코더 모듈과 그리고 생성기로부터 학습된 맵핑의 역구조를 추가해 GAN 프레임웍 확장을 제안한다.

최적의 판별기의 한계는 [4]는 결정론적인 BiGAN은 오토인코더와 같은 방식으로 A의 reconstruction 비용$(l_0)$을 최소화 하는것을 보여준다; 그러나 재구성 오차 표면의 형상은 L2 오류와 같은 단순한 픽셀수준 지표와는 반대로 생성기의 파라미터에 의해 좌우된다. 판별기는 종종 강력한 뉴럴넷이 되지만, 그 희망은 저수준 디테일 보다는 재구성의 의미 오류를을 유도하는 것이다.

[4]에서 BiGAN 또는 ALI 를 통해 학습된 인코더가 이미지넷에서의 다운스트림 작업을 위한 시각적 표현 학습의 방법으로 효과적인 것을 증명했다. 그러나 이것은 DCGAN 스타일의 생성기를 사용하였고, 이 데이터셋에서 고해상도 이미지를 생성하지 못하기 떄문에 인코더가 모델링 할 수 있는 의미가 상당히 제한적이다. 이 연구에서 우리는 
ImageNet에 존재하는 많은 구조와 모드를 캡쳐 가능해 보이는 현대 모델인 BigGAN을 생성기로 사용하는 접근방식을 다시 살펴볼 것이다. 다음 방식을 따른다.

- 우리는 BigBiGAN(BigGAN생성기를 사용한 BiGAN)이 ImageNet의 비지도 표현 학습에서 SOTA인 것을 보여준다.
- BigBiGAN에 생성기를 적용하기 위한 더 안정적인 버전을 제안한다.
- 모델 디자인 선택을 위한 철저한 경험적인 분석과 연구를 수행한다.
- 표현학습이 객관적으로 조건없는 이미지 생성을 도와줄 수 있고, 조건없는 ImageNet 생성에서 SOTA 결과가 나온것을 증명한다.


# 2. BigBiGAN

BiGAN 또는 ALI 접근은 GAN 프레임웍의 확장모델인데 모델 추론 또는 피쳐 표현으로 사용 가능한 인코더의 학습을 활성화였다. 데이터의 분포 $P_x$와 latents $z$ 의 분포 $P_z$(일반적으로 평균이 0인 가우시안 분포) 가 주어지고, 생성기 $\mathcal{G}$ 는 $P_z$ 공간에서 샘플링된 $z$ 가 주어진 데이터 $x$ 의 조건부 분포 $P(x\|z)$ 를 모델링 한다. 마치 일반 GAN 생성기 처럼. 인코더 $\mathcal{E}$는 조건부 분포의 반대인 $P(z\|x)$를 모델링하고, 데이터의 분포 $P_x$에서 샘플링된 $x$가 주어졌을때의 latent $z$ 를 예측한다.

인코더 $\mathcal{E}$ 가 추가된것 외에, BiGAN 프레임웍 안에 있는 GAN에 대한 다른 수정으로는 입력 쌍인 $(x,z)$(일반적인 GAN의 x와는 다르다)를 취하는 판별기 $\mathcal{D}$를 병합하고, (데이터 분포와 인코더) 대 (생성기와 latent 분포) 쌍 사이의 차이를 학습한다. 구체적으로 입력 은 $(x \sim P_x, \hat{z} \sim \mathcal{E}(x))$ 와 $(\hat{x} \sim \mathcal{G}(z), z \sim P_z)$ 이고, $\mathcal{G}$ 와 ${E}$ 의 목적은 구분할 수 없게 샘플링된 쌍 $P_{x\mathcal{E}}$ 와 $P_{\mathcal{G}z}$ 두개의 결합 분포를 만듬으로 판별기를 속이는 것이다. [4,7]에 나온 adversarial minimax objective, GAN의 프레임웍과 유사한 것으로 다음과 같이 정의된다.

$$
\underset{\mathcal{GE}}{min}\underset{\mathcal{D}}{max}

\left\{
    \mathbb{E}_{x\sim P_x, z \sim \mathcal{E}_\Phi(x)} 
    [\log(\sigma(\mathcal{D}(x,z)))] + 

    \mathbb{E}_{z\sim P_z, x \sim \mathcal{G}_\Phi(z)} 
    [\log(1 - \sigma(\mathcal{D}(x,z)))]
\right\}

$$

## 확인 후 수정 필요
이 목적함수를 사용한 [4,7]은 최적의 $\mathcal{D,G, E}$ 가 결합분포 $P_{x\mathcal{E}}$ 와 $P_{\mathcal{G}z}$ 사이의 젠슨샤논 발산을 최소화하는 것을 보여주는데다,  전역 최적점에서는 두 결합분포가 같아지고, 일반적은 GAN의 결과와 유사해진다. 더 나아가, [4]에서는 $\mathcal{E,G}$가 결정함수인 경우(예를들면 조건부분포 $P_{\mathcal{G}(x|z)}$, $P_{\mathcal{E}(z|x)}$ 가 디랙델타 함수일때), 이 두 함수가 $x, z$에 재구성 비용을 효과적으로 나타내는 최적의 결합 판별기 와 함께 전역 최적점에서 역행하는 것을 보여준다.

BigBiGAN의 핵심은 BiGAN과 같고 SOTA인 BigGAN의 생성기와 판별기를 적용하였다.
거기에 더하여, 생성기와 타협하지 않고 좋은 표현 학습 결과를 이끄는 향상된 판별기 구조를 찾았다. 즉 [4,7]에서 제안된 데이터와 latent분포를 함꼐 묶는 결합판별기 손실 이외에, 추가적인 짧은 학습 목표를 추가했고 이것은 오직 x나 latent에만 관련된 함수이다. 비록 [4,7]에서 기존 BiGAN의 목적함수로 학습된 결합 분포가 전역 최적점과 일치하는것은 입증 햇지만 $x,z$의 한계분포도 일치함을 암시한다.
이 속성을 명시적으로 적용해 이 짧은 텀이 직관적으로 좋은 방향으로 최적화를 유도한다.
예를들면, 이미지 생성에서 이 $x$에 관한 단항의 손실이 기존 GAN의 목적함수와 매치해주고, latent 입력에 독립적으로 이미지분포가 매칭되도록 생성기를 조종하는 학습신호를 제공한다.

구체적으로, 판별기의 로스 $\mathcal{L_D}$ 과 인코더와 생성기 로스 $\mathcal{L_{EG}}$ 는 다음과 같이 정의된다. 판별기의 점수 함수 $s_\*$ 와 샘플별 로스에 해당하는 $l_*$을 기반으로 한다.

$$
s_x(x)= \theta^T_x F_{\Theta}(x) \\
s_z(z)= \theta^T_z F_{\Theta}(z) \\
s_{xz}(x,z)=\theta^T_{xz} J_\Theta(F_\Theta(x), H_\Theta(z)) \\
\mathcal{l_{EG}}(x,z,y) = y(s_x(x) + s_z(z) +s_{xz}(x,z))) \\
\mathcal{L_{EG}}(P_x, P_z) = 
    \mathbb{E}_{x \sim P_x, \hat{z} \sim \mathcal{E}_\Phi(x)}
    [\mathcal{l_{EG}(x,\hat{z},+1)}] +
    \mathbb{E}_{z \sim P_z, \hat{x} \sim \mathcal{G}_\Phi(z)}
    [\mathcal{l_{EG}(\hat{x},z,-1)}] \\

\mathcal{l_D}(x,z,y) = h(ys_x(x)) + h(ys_z(z)) + h(ys_{xz}(x,z)) \\
\mathcal{L_D}(P_x, P_z) = 
    \mathbb{E}_{x \sim P_x, \hat{z} \sim \mathcal{E}_\Phi(x)}
    [\mathcal{l_D(x,\hat{z},+1)}] +
    \mathbb{E}_{z \sim P_z, \hat{x} \sim \mathcal{G}_\Phi(z)}
    [\mathcal{l_D(\hat{x},z,-1)}] \\
$$

$h(t) = max(0,1-t)$ 는 판별기를 정규화하는데 사용한 힌지손실이고 BigGAN에서도 사용된다. 판별기는 $F, H, J$ 3개의 작은 서브모듈을 포함한다. $F$는 x, $H$는 z 만을 입력을  사용하고, 그들의 출력과 상수 $s_x, s_z$ 가 주어진   $\theta_x, \theta_z$을 투영하여 학습한다. 우리 실험에서 데이터 $x$ 는 이미지, latent $z$ 는 1차원 벡터이다.그리고 $F$ 는 ConvNet, $H$ 는 MLP이다. $x$와$z$를 묶은 결합점수 $s_{xz}$는 $\mathcal{D}$ 서브 모듈과 $\mathcal{J}$, 그리고 $F,H$ 함수의 출력에 주어진다.

$\mathcal{E,G}$의 파라미터 $\Phi$는 $\mathcal{L_{EG}}$를 최소화 하는것으로 최적화되고, $\mathcal{D}$ 의 파라미터 $\Theta$는 $\mathcal{L_D}$를 최소화 하여 최적화된다. 기대값들인 $\mathbb{E}$는 미니배치에서 취한 몬테카를로 샘플링 방식으로 추정된다. 

# 3. Evaluation 

우리실험은 거의 [37]에서 처음 제안된 비지도 학습 기법을 평가하는 일반적인 방식을 따랐다. BigBiGAN을 라벨없는 이미지에서 학습후 고정시키고, 선형 분류기를 결과에 추가하고, 모든 트레이닝셋의 라벨에 대하여 지도학습을 하였다. 또한 이미지 생성 성능을 측정하기 위해, 기존 측정법인 Inception Score 를 기록하고, Frechet Inception Distance(FID)를 사용했다.

## 3.1 Ablation (요약?)

선택된 모델링의 수에 따라 직접적으로 평가하고 광범위한 요약을 시작했다. 테이블 1에 결과가 나와있다. 가능한 각각 다른 시드를 주어 3번이상수행 했고 모든 지표의 평균과 표준편차에 대해 기록했다.

128해상도에선 상대적으로 완전하게 시작되었다. $\mathcal{G}$의 구조와 판별기의 $F$는 BigGAN의 128 구조를 사용했고, 스킵커넥션을 추가하고 [1]에 제안된 임베딩된 노이즈 셰어링을 사용하였다. z 는 120차원이고 6그룹으로 나뉘어 20차원씩 제네레이터의 6레이어에 각각 들어갔다. 남은 컴퓨넌트인 H와 J 는 ResNet 스타일의 스킵커넥션이 들어간 8층의 MLP로 구성 (2 층씩 4개의 residual blocks)하고 2048의 유닛을 가지고 있다. $\mathcal{E}$ 는 ResNet-v2-50 기본을 사용하고 GAP를 추가 후 스킵커넥션이 추가된 4개의 4096유닛의 4층 레이어를 추가하였다 (2층씩 2개의 residual block). 
비조건 BigGAN의 학습은 [24]에서 제안된 설정인 Single Label 에 해당하는 방법을 사용하였고, 한가지의 더미 레이블을 모든 이미지에 사용하였다. (이론적으로는 클래스조건 입력 대신에 편향을 학습하는 것과 같다). 이후 뒤에 상세히 기술한 결과를 가지고 모델의 몇가지 측면을 제거했다. 추가적인 구조나 최적화 디테일은 부록A 에 제공된다.
많은 결과에 대한 전체 학습 곡선 은 부록 D에 포함되어 있다.

### Latent distribution $P_z$ and Stochastic $\mathcal{E}$
ALI에 따르면, 우리 모델의 인코더 $E$ 는 비결정적이고, 분포 $\mathcal{N}(\mu, \sigma)$ 를 수정한다. $\mu, \hat\sigma$는 모델의 출력에 선형 층으로 주어지고, 최종 표준편차인 $\sigma$는 비선형인 비음수함수 softplus로 계산된다 $\sigma = \log(1+\exp(\hat\sigma))$. 최종 $z$는 $z = \mu + \epsilon\sigma, \epsilon \sim \mathcal{N}(0,I)$을 사용한다. deterministic 인코더와 다르게 샘플링 없이 바로 $z$를 예측 가능하고, 비결정적 기반 모델이 상당히 더 높은 분류 성능을 달성했다(생성 부분에서 비용 없이). 또한 BiGAN에서 사용한 선형출력인 $\hat{z}$을 입력으로 $z = \tanh(\hat{z})$ 함수를 사용하는 균등 분포$P_z = \mathcal{U}(-1,1)$ 와도 비교를 해보았지만 이또한 비결정적 기반 모델에 비해 낮은 분류결과가 나타났다.

### Unary loss terms
하나 혹은 양쪽의 unary 로스를제거해가며 성능을 평가 해봤다. 양쪽을 제거하는것은 원래 BiGAN 의 목적함수에 해당한다. $x$텀을 가지는 방법이 생성기 퍼포먼스에 매우 긍정적인 영향을 끼친다. 기본과 x unary만 있는것이 IS 와 FID에서 z unary 만 가진것이나 추가항 이 없는것 보다 훨씬 좋은 결과를 가진다. 이 결과는 일반적인 생성기 로스와 일치하므로 직관적으로 볼 수 있어진다. z unary 텀은 좀더 미미한 변화를 만든다, 아마도 모델이 isotropic 정규분포처럼 간단한 분포여서 모델링시 쉬워서 그런듯 하다.
또한 분류와 생성의 FID 면에서 조금 향상되는 결과를 가져온다 (x unary 없이).
반면에, IS 는 z term 과 함께하면 나빠진다. 아마도 IS 는 생성기의 전체분포 보다 주요한 부분의 분포를 측정하기 때문이다. FID가 잘나오는것보다는 좋은 인코더에 의해 촉진되는것이 좋다. BiGAN에서 반전의 필요는 다양한 latent 공간을 단일한 데이터 분포로 축소하는 대신 생성기를 distinguishable 전체 latent 공간에 걸쳐 구분가능한 출력을 생성하도록 유도하는 것일 수 있다. 

### $\mathcal{G}$ capacity
표현학습에서 생성기의 중요성에 대한 질문을 위해 $\mathcal{G}$의 용량을 1/3 정도로(small $\mathcal{G}$ = 32) 다르게 했다($\mathcal{E,G}$는 고정). 전반적인 모델은 약간 불안정했고 고용량의 기본모델에 비해 현저히 나쁜 분류결과가 나왔고, 2/3 용량(64)에서는 생성 성능이 상당히 나쁘고 분류성능도 별로 좋지 않았다. 이 결과는  인코더를 통해 좋은 표현을 배우기 위해 필요한것은 고성능의 생성기라는 것을 확인시켰다. 
이 관계가 유지된다면 우리는 더 좋은 생성모델을 쓰느것이 곧 표현학슴을 더 향상시키는 것과 같다는 것을 예상 할 수 있다.

### StandardGAN 
또한 인코더가 없는 조건없는 BigGAN에 판별기에 F ConvNet만 있고 손실엔 $s_x$ 텀만 가지고도 이미지 생성 성능을 비교했다. 기본 GAN은 아주 조금 좋은 IS, 같은 FID, 그리고 새로운 손실항이 추가된 인코더와 판별기의 추가가 성능을 저해하지 않음을 보였다(섹션 2). (이에 반해, $x$텀이 없는 모델은 FID 에서 표준 GAN보다 훨씬 나쁜 생성 성능을 보인다.) IS는 $s_z$텀과 비슷한 이유로 성능이 나빠진다고 생각한다. 다음은 고해상도 입력으로 $\mathcal{E}$가 강화되는 것과, BiGBiGAN의 생성기가 FID에서 표준보다 상당히 향상되는것을 보여줄 것이다.

###













