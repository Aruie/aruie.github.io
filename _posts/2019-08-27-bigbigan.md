---
layout: post
title:  "BigGAN + BiGAN = BigBiGAN: New State-of-the art Model In Representation Learning"
tag : Paper
date : 2019-08-27 10:05:05 +0900
comments: true
---

항상 대형모델 제목엔 소타가...
맨날 소타래

# Abstract

GAN들은 최근 매력적인 이미지 합성 결과를 달성했다.
초기에 비지도표현학습 방식을 사용한 GAN의 성공에도 불구하고, 이후엔 self-supervision(vised) 방식으로 대체되었다.
이 연구에서 우리는 이미지 생성 퀄리티의 향상이 표현학습 퍼포먼스를 상당히 향상 시키는것을 보여준다.
우리의 BigBiGAN은 SOTA 모델인 BigGAN 모델을 기반으로, 인코더를 추가하고 판별기를 수정하여 표현학습 과정을 확장하였다.
우리는 이 BigBiGAN 모델들의 representation learning 과 생성 능력을 광범위하게 평가하고, 이 생성기반모델들이 이미지넷에서의 비지도표현학습과 조건없는 이미지 생성에서 SOTA를 달성한 것을 보여준다.


# 1. Introduction

최근 몇년 동안 비전데이터 생성 모델들은 빠른 진보를 보아왔다. 이 모델들은 적은 모드, 간단한 구조, 그리고 저해상도라는 조건들에 국한되었지만, 모델링과 하드웨어의 발전으로 복잡하고 여러모드를 가지 고해상도 이미지 분포를 리얼하게 생성할 수 있는 능력을 얻게 되었다.
직관적으로, 이 특정 도메인의 데이터 생성 능력은 해당 도메인에 대한 높은 수준의 이해가 필요하다. 이 생각은 데이터가 많고 가격이 낮아져 전형적인 대부분 분류 머신러닝 모델이 예측할 라벨보다 훨씬 더 많은 정보로 구성된 이미지와 함께 오랫동안 인기를 끌고있다.
생성모델이의 발전은 명백했지만, 해결되지않는 질문이 있었다 : 이 모델이 배운 의미는 무엇이며 어떻게 그들이 표현학습에 영향을 주는지를.

원시 데이터만으로 진실을 이해하는 수준이 되려는 생성의 궁극적인 목표는 아직 거의 실현되지 않았다. 대신, 대부분 자기지도학습을 위한 대부분의 성공적인접근법은 자기지도학습이라 불리는 지도학습 분야를 적용하는 것이다. 이 접근법들은 일반적으로 데이터의 특정 부분을 변경하거나 고정하고, 누락된 정보 부분을 생성하거나 예측하는 모델을 학습하는것을 포함한다. 예를들면 [37,38] 에서는 비지도방식으로 채색하는것을 제안했고, 모델에게 입력 이미지의 색상채널에 일부분만 주고 빠진 채널을 예측하는 방식이다. 

비지도학습방식의 생성 모델들은 원래의 데이터의 어떤 수정도 필요로하지 않는 전체 데이터 분포를 모델링 하도록 학습되는 자기지도학습을 위한 매력적인 제안을 제공한다.
생성모델의 한 종류는 GAN이다. GAN 프레임웤의 생성기는 랜덤 샘플링된 latent 값으로 부터 feed-foward 맵핑을 통해 데이터를 생성하고, 실제 데이터와 생성된 데이터 샘플 사이의 차이를 학습하는 판별기가 제공하는 신호를 통해 제네레이터가 데이터의 출력이 데이터의 분포를 따르도록 안내한다. ALI(Adversirially learned inference) 혹은 BiGAN 접근법은 기본 GAN의 구조에, 실제 데이터를 latents로 맵핑하는 인코더 모듈과 그리고 생성기로부터 학습된 맵핑의 역구조를 추가해 GAN 프레임웍 확장을 제안한다.

최적의 판별기의 한계는 [4]는 결정론적인 BiGAN은 오토인코더와 같은 방식으로 A의 reconstruction 비용$(l_0)$을 최소화 하는것을 보여준다; 그러나 재구성 오차 표면의 형상은 L2 오류와 같은 단순한 픽셀수준 지표와는 반대로 생성기의 파라미터에 의해 좌우된다. 판별기는 종종 강력한 뉴럴넷이 되지만, 그 희망은 저수준 디테일 보다는 재구성의 의미 오류를을 유도하는 것이다.

[4]에서 BiGAN 또는 ALI 를 통해 학습된 인코더가 이미지넷에서의 다운스트림 작업을 위한 시각적 표현 학습의 방법으로 효과적인 것을 증명했다. 그러나 이것은 DCGAN 스타일의 생성기를 사용하였고, 이 데이터셋에서 고해상도 이미지를 생성하지 못하기 떄문에 인코더가 모델링 할 수 있는 의미가 상당히 제한적이다. 이 연구에서 우리는 
ImageNet에 존재하는 많은 구조와 모드를 캡쳐 가능해 보이는 현대 모델인 BigGAN을 생성기로 사용하는 접근방식을 다시 살펴볼 것이다. 다음 방식을 따른다.

- 우리는 BigBiGAN(BigGAN생성기를 사용한 BiGAN)이 ImageNet의 비지도 표현 학습에서 SOTA인 것을 보여준다.
- BigBiGAN에 생성기를 적용하기 위한 더 안정적인 버전을 제안한다.
- 모델 디자인 선택을 위한 철저한 경험적인 분석과 연구를 수행한다.
- 표현학습이 객관적으로 조건없는 이미지 생성을 도와줄 수 있고, 조건없는 ImageNet 생성에서 SOTA 결과가 나온것을 증명한다.


# 2. BigBiGAN

BiGAN 또는 ALI 접근은 GAN 프레임웍의 확장모델인데 모델 추론 또는 피쳐 표현으로 사용 가능한 인코더의 학습을 활성화였다. 데이터의 분포 $P_x$와 latents $z$ 의 분포 $P_z$(일반적으로 평균이 0인 가우시안 분포) 가 주어지고, 생성기 $\mathcal{G}$ 는 $P_z$ 공간에서 샘플링된 $z$ 가 주어진 데이터 $x$ 의 조건부 분포 $P(x\|z)$ 를 모델링 한다. 마치 일반 GAN 생성기 처럼. 인코더 $\mathcal{E}$는 조건부 분포의 반대인 $P(z\|x)$를 모델링하고, 데이터의 분포 $P_x$에서 샘플링된 $x$가 주어졌을때의 latent $z$ 를 예측한다.

인코더 $\mathcal{E}$ 가 추가된것 외에, BiGAN 프레임웍 안에 있는 GAN에 대한 다른 수정으로는 입력 쌍인 $(x,z)$(일반적인 GAN의 x와는 다르다)를 취하는 생성기 $\mathcal{D}$를 병합하고, (데이터 분포와 인코더) 대 (생성기와 latent 분포) 쌍 사이의 차이를 학습한다. 구체적으로 입력 은 $(x \sim P_x, \hat{z} \sim \mathcal{E}(x))$ 와 $(\hat{x} \sim \mathcal{G}(z), z \sim P_z)$ 이고, $\mathcal{G}$ 와 ${E}$ 의 목적은 구분할 수 없게 샘플링된 쌍 $P_{x\mathcal{E}}$ 와 $P_{\mathcal{G}z}$ 두개의 결합 분포를 만듬으로 판별기를 속이는 것이다. [4,7]에 나온 adversarial minimax objective, GAN의 프레임웍과 유사한 것으로 다음과 같이 정의된다.

$$
\underset{\mathcal{GE}}{min}\underset{\mathcal{D}}{max}

\left\{
    \mathbb{E}_{x\sim P_x, z \sim \mathcal{E}_\Phi(x)} 
    [\log(\sigma(\mathcal{D}(x,z)))] + 

    \mathbb{E}_{z\sim P_z, x \sim \mathcal{G}_\Phi(z)} 
    [\log(1 - \sigma(\mathcal{D}(x,z)))]
\right\}

$$

## 수정 필요
이 목적함수를 사용한 [4,7]은 최적의 $\mathcal{D,G, E}$ 가 결합분포 $P_{x\mathcal{E}}$ 와 $P_{\mathcal{G}z}$ 사이의 젠슨샤논 발산을 최소화하는 것을 보여주는데다,  전역 최적점에서는 두 결합분포가 같아지고, 일반적은 GAN의 결과와 유사해진다. 더 나아가, [4]에서는 $\mathcal{e,g}$가 결정함수인 경우, 이 두 함수가 전역 최적점의 inverses 인것을 보여준다, $x, z$에 재구성 비용을 효과적으로 부여하는 최적의 결합 판별기.

BigBiGAN의 핵심은 BiGAN과 같고 SOTA인 BigGAN의 생성기와 판별기를 적용하였다.
거기에 더하여, 생성기와 타협하지 않고 좋은 표현 학습 결과를 이끄는 향상된 판별기 구조를 찾았다. 즉 [4,7]에서 제안된 데이터와 latent분포를 함꼐 묶는 결합판별기 손실 이외에, 추가적인 짧은 학습 목표를 추가했고 이것은 오직 x나 latent에만 관련된 함수이다. 비록 [4,7]에서 기존 BiGAN의 목적함수로 학습된 결합 분포가 전역 최적점과 일치하는것은 입증 햇지만 $x,z$의 한계분포도 일치함을 암시한다.
이 속성을 명시적으로 적용해 이 짧은 텀이 직관적으로 좋은 방향으로 최적화를 유도한다.
예를들면, 이미지 생성에서 이 $x$에 관한 단항의 손실이 기존 GAN의 목적함수와 매치해주고, latent 입력에 독립적으로 이미지분포가 매칭되도록 생성기를 조종하는 학습신호를 제공한다.










