---
layout: post
title:  "TransGAN : Two Transformers Can Make One Strong GAN"
tag : "Paper Review"
date : 2021-02-21 10:05:05 +0900
comments: true
---



# Abstract
- 현재 보편적인 CV 태스크에서 transformer는 매우 각광받고있다
- 하지만 더나아가 GAN 같은 어려운 태스크에서도 잘될것인가
- 컨볼루션에서 완전히 벗어난 GAN을 생성함
- TransGAN이라 부르며 memory-frendly transformer 기반 generator 를 사용하여 progressively 증가하는동안 임베딩 차원은 줄어든다
- 그리고 패치단위 discriminator 또한 gransformer 기반이다
- 아방식은 데이터 augmentation, generator의 multy task co-training, 부분적인 이미지의 평활함에 강점이 있다
- 효과적으로 큰모델과 함께 고해상도 이미지 데이터에 적용할수 있다
- 현재 ConvNet 기반 SOTA 모델들과도 큰 차기아 나지않는다
- 이방식의 한계점과 가능성에 대해 탐구한다

# 1.1 Our Contributions
- 오직 transformer 만을 사용한 최초의 completely free of convolution 모델
  - 기존의 인코더 블록에만 적용한 방식과는 완전히 다름
- 기존 transformer 기반 CV모델들은 classification 혹은 detection에만 주로 사용되었기에 다른 문제가 발생
  - 구조나 색상, 질감 등의 공간적인 일관성에도 효과가 좋은지 분명하지 않음
- 이미지를 출력하는 몇안되는 transformer 기반 모델은 하나같이 convolution 기반의 encoder를 사용함
  - visual transformer 학습은 무겁고 매우 어렵기로 알려져 있다
  - GAN은 일반적으로 불안정하고 mode collapse가 쉽게 일어남
  - 두가지 문제가 더해져 매우 어려운 도전임
- 이것을 해결하기 위한 노력과 혁신적인 방법들을 공개함

- Contribution
  - Model Architecture
    - Purely transformers and no convolution
    - Memory friendly generator and a patch-level discriminator
    - Effiectively scaled up to larger models

  - Training Technique
    - Data Augmentation
    - Multi-task co-training for generator with self-supervised auxiliary loss
    - localized initailization



# 3. Technical Approach
  - A Journey Towards GAN with Pure Transformers
    - GAN은 Generator 와 Discriminator 로 구성되고 이 두가지를 transformer로 변경하는 것으로 시작
    - 둘다 메모리 효율적인 구조로 대체하여 vanilla TransGAN을 구성
    - 이후 약점을 보완할 테크닉들을 하나씩 도입하여 deeper / wider model을 만들고 높은 퀄리티의 이미지를 생성함
## 3.1 Vanilla Architecture Design for TransGAN
- Transformer Encoder as Basic Block
  - Image Transformer (Vaswani et al., 2017) 구조를 채용
    - 인코더는 multy-head self-attention 과 feed-forward with GELU 로 구성됨
  - layer normalization을 두가지 파트양쪽 앞에 적용하고 residual connection 을 사용
- Memory Frendly Generator
  - 이미지는 작은 이미지도 픽셀단위 시퀸스로 변화하면 매우 커질수 있어 self-attention에서 매우 큰 비용이 발생한다
  - PGGAN에서 영감읋 받아 점진적으로 증가하며 해상도가 높아질수록 Embedding 사이즈를 줄이는 방식을 사용
    - multiple stages로 구성되며 매 stage마다 목표 해상도가 될 때까지 두배씩 커짐
    - 매 stage에는 encoder block 이 수회 반복됨
  - noise input을 바로 사용하지않고 MLP를 통과 후 $H \times W \times C$ 크기를 가진 vector로 변경 후 learnable 한 positinal encoding 을 추가
  - upsampling을 위해 매 스테이지 뒤에 pixelshuffle 모듈을 사용
    - 우선 1D로 된 sequence를 2D로 변경 후 pixelshuffle를 적용해 2배 upsample을 하고 dimension 을 1/4로 줄인 후 1D sequence로 변화시킴 (sequence가 변하지 않음)
    - 최종적으로 목표 해상도에 도달했을때 channel을 3으로 조정
    - 이방식으로 memory and computation exposion을 완화함
- Tokenized-Input For Discriminator
  - 픽셀을 정확히 예측해야하는 Generator 와는 다르게 discriminator는 오직 real / fake 의 분류만 하면 된다
    - 이것은 입력 이미지를 patch 레벨로 tokenizing 하는것을 허용하게 해준다
  - 이미지를 $8 \times 8$패치로 나누고 각각 flatten을 거쳐 마치 word 인것마냥 [cls] 토큰을 추가
  - 이후 leanable token embedding을 거치고 [cls] 토큰의 출력만으로 real / fake 분류를 한다
- Evaluation of Transformer-based GAN
  - transformer 기반 
## 3.2 
  - 
    - 
    - 








